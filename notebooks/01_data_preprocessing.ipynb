{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìä IMDb Sentiment Analysis - Data Preprocessing\n",
        "\n",
        "This notebook demonstrates the complete data preprocessing pipeline for IMDb sentiment analysis, including:\n",
        "- Data loading and validation\n",
        "- Text cleaning and preprocessing\n",
        "- TF-IDF vectorization\n",
        "- Exploratory data analysis\n",
        "- Feature engineering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Add src to path - more robust path handling\n",
        "import sys\n",
        "import os\n",
        "current_dir = os.getcwd()\n",
        "src_path = os.path.join(current_dir, '..', 'src')\n",
        "if os.path.exists(src_path):\n",
        "    sys.path.insert(0, src_path)\n",
        "    print(f\"‚úÖ Added {src_path} to Python path\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Warning: {src_path} not found, trying alternative paths...\")\n",
        "    # Try alternative paths\n",
        "    alt_paths = [\n",
        "        os.path.join(current_dir, 'src'),\n",
        "        os.path.join(os.path.dirname(current_dir), 'src'),\n",
        "        'src'\n",
        "    ]\n",
        "    for alt_path in alt_paths:\n",
        "        if os.path.exists(alt_path):\n",
        "            sys.path.insert(0, alt_path)\n",
        "            print(f\"‚úÖ Added {alt_path} to Python path\")\n",
        "            break\n",
        "    else:\n",
        "        print(\"‚ùå Could not find src directory\")\n",
        "\n",
        "# Import with error handling\n",
        "try:\n",
        "    from preprocessing import TextPreprocessor, validate_data, load_imdb_data\n",
        "    print(\"‚úÖ Successfully imported preprocessing modules!\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Import error: {e}\")\n",
        "    print(\"Please ensure you're running this notebook from the notebooks/ directory\")\n",
        "    print(\"and that the src/ directory exists with the required Python files.\")\n",
        "    # You can still continue with basic functionality\n",
        "    print(\"Continuing with basic imports...\")\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load and Explore Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the IMDb dataset\n",
        "dataset_path = \"../IMDB Dataset.csv\"\n",
        "df = load_imdb_data(dataset_path)\n",
        "\n",
        "if df is not None:\n",
        "    print(f\"‚úÖ Dataset loaded successfully!\")\n",
        "    print(f\"üìä Dataset shape: {df.shape}\")\n",
        "    print(f\"üìã Columns: {list(df.columns)}\")\n",
        "    print(f\"üîç Data types:\\n{df.dtypes}\")\n",
        "else:\n",
        "    print(\"‚ùå Failed to load dataset. Please check the file path.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Validation and Quality Assessment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate the dataset\n",
        "print(\"üîç Data Validation Report\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check for missing values\n",
        "print(\"üìä Missing Values Analysis:\")\n",
        "print(f\"Missing values in 'review': {df['review'].isna().sum()}\")\n",
        "print(f\"Missing values in 'sentiment': {df['sentiment'].isna().sum()}\")\n",
        "\n",
        "# Check for duplicates\n",
        "duplicates = df.duplicated().sum()\n",
        "print(f\"\\nüîÑ Duplicate Analysis:\")\n",
        "print(f\"Total duplicates: {duplicates}\")\n",
        "\n",
        "# Check class distribution\n",
        "print(f\"\\nüìà Class Distribution:\")\n",
        "class_counts = df['sentiment'].value_counts()\n",
        "print(class_counts)\n",
        "print(f\"\\nClass balance:\")\n",
        "for sentiment, count in class_counts.items():\n",
        "    percentage = (count / len(df)) * 100\n",
        "    print(f\"{sentiment}: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "# Check text length statistics\n",
        "print(f\"\\nüìè Text Length Statistics:\")\n",
        "df['text_length'] = df['review'].str.len()\n",
        "print(df['text_length'].describe())\n",
        "\n",
        "# Check for very short or very long reviews\n",
        "short_reviews = (df['text_length'] < 10).sum()\n",
        "long_reviews = (df['text_length'] > 10000).sum()\n",
        "print(f\"\\n‚ö†Ô∏è  Quality Issues:\")\n",
        "print(f\"Very short reviews (< 10 chars): {short_reviews}\")\n",
        "print(f\"Very long reviews (> 10,000 chars): {long_reviews}\")\n",
        "\n",
        "# Validate data using our validation function\n",
        "print(f\"\\n‚úÖ Data Validation:\")\n",
        "is_valid = validate_data(df)\n",
        "print(f\"Dataset is valid: {is_valid}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Exploratory Data Analysis (EDA)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample reviews for inspection\n",
        "print(\"üìù Sample Reviews:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Show sample positive and negative reviews\n",
        "positive_samples = df[df['sentiment'] == 'positive']['review'].head(2)\n",
        "negative_samples = df[df['sentiment'] == 'negative']['review'].head(2)\n",
        "\n",
        "print(\"üåü Positive Reviews:\")\n",
        "for i, review in enumerate(positive_samples, 1):\n",
        "    print(f\"{i}. {review[:200]}...\")\n",
        "    print()\n",
        "\n",
        "print(\"üòû Negative Reviews:\")\n",
        "for i, review in enumerate(negative_samples, 1):\n",
        "    print(f\"{i}. {review[:200]}...\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize class distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Class distribution pie chart\n",
        "class_counts = df['sentiment'].value_counts()\n",
        "axes[0].pie(class_counts.values, labels=class_counts.index, autopct='%1.1f%%', \n",
        "           colors=['lightcoral', 'lightblue'], startangle=90)\n",
        "axes[0].set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Text length distribution by sentiment\n",
        "positive_lengths = df[df['sentiment'] == 'positive']['text_length']\n",
        "negative_lengths = df[df['sentiment'] == 'negative']['text_length']\n",
        "\n",
        "axes[1].hist([positive_lengths, negative_lengths], bins=50, alpha=0.7, \n",
        "            label=['Positive', 'Negative'], color=['lightblue', 'lightcoral'])\n",
        "axes[1].set_xlabel('Text Length (characters)')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "axes[1].set_title('Text Length Distribution by Sentiment', fontsize=14, fontweight='bold')\n",
        "axes[1].legend()\n",
        "axes[1].set_xlim(0, 2000)  # Focus on reasonable range\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print statistics\n",
        "print(\"üìä Text Length Statistics by Sentiment:\")\n",
        "print(\"=\" * 50)\n",
        "print(\"Positive Reviews:\")\n",
        "print(positive_lengths.describe())\n",
        "print(\"\\nNegative Reviews:\")\n",
        "print(negative_lengths.describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Text Preprocessing Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the text preprocessor\n",
        "print(\"üîß Initializing Text Preprocessor\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "preprocessor = TextPreprocessor(\n",
        "    max_features=5000,  # Maximum number of features for TF-IDF\n",
        "    min_df=2,          # Minimum document frequency\n",
        "    ngram_range=(1, 2) # Unigrams and bigrams\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Preprocessor initialized with:\")\n",
        "print(f\"   - Max features: {preprocessor.max_features}\")\n",
        "print(f\"   - Min document frequency: {preprocessor.min_df}\")\n",
        "print(f\"   - N-gram range: {preprocessor.ngram_range}\")\n",
        "\n",
        "# Demonstrate text cleaning on sample reviews\n",
        "print(f\"\\nüßπ Text Cleaning Demonstration:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "sample_reviews = [\n",
        "    \"<p>This movie was <b>fantastic</b>! It's amazing! Check out http://example.com</p>\",\n",
        "    \"Don't watch this terrible movie. It's awful and boring.\",\n",
        "    \"Outstanding performances by all actors. Highly recommended!\"\n",
        "]\n",
        "\n",
        "for i, review in enumerate(sample_reviews, 1):\n",
        "    print(f\"Sample {i}:\")\n",
        "    print(f\"Original:  {review}\")\n",
        "    cleaned = preprocessor.clean_text(review)\n",
        "    print(f\"Cleaned:   {cleaned}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply preprocessing to the entire dataset\n",
        "print(\"üîÑ Applying Preprocessing Pipeline\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Preprocess the dataframe\n",
        "df_processed = preprocessor.preprocess_dataframe(\n",
        "    df, \n",
        "    text_column='review', \n",
        "    label_column='sentiment',\n",
        "    remove_stopwords_flag=True\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Preprocessing completed!\")\n",
        "print(f\"Original dataset size: {len(df)}\")\n",
        "print(f\"Processed dataset size: {len(df_processed)}\")\n",
        "print(f\"Removed: {len(df) - len(df_processed)} samples\")\n",
        "\n",
        "# Show before and after examples\n",
        "print(f\"\\nüìù Before vs After Preprocessing Examples:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "sample_indices = [0, 100, 1000]  # Sample different reviews\n",
        "for idx in sample_indices:\n",
        "    if idx < len(df) and idx < len(df_processed):\n",
        "        original = df.iloc[idx]['review']\n",
        "        processed = df_processed.iloc[idx]['review']\n",
        "        sentiment = df_processed.iloc[idx]['sentiment']\n",
        "        \n",
        "        print(f\"Sample {idx} ({sentiment}):\")\n",
        "        print(f\"Original:  {original[:150]}...\")\n",
        "        print(f\"Processed: {processed[:150]}...\")\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Feature Engineering with TF-IDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for training\n",
        "print(\"üéØ Preparing Data for Training\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Use the complete preprocessing pipeline\n",
        "X_train, X_test, y_train, y_test, fitted_preprocessor = preprocessor.prepare_data(\n",
        "    df, \n",
        "    text_column='review', \n",
        "    label_column='sentiment',\n",
        "    test_size=0.2, \n",
        "    random_state=42,\n",
        "    remove_stopwords_flag=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Data preparation completed!\")\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "print(f\"Number of features: {X_train.shape[1]}\")\n",
        "print(f\"Training labels shape: {y_train.shape}\")\n",
        "print(f\"Test labels shape: {y_test.shape}\")\n",
        "\n",
        "# Check class distribution in train/test sets\n",
        "print(f\"\\nüìä Class Distribution in Train/Test Sets:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Get class names from label encoder\n",
        "class_names = fitted_preprocessor.label_encoder.classes_\n",
        "print(f\"Class names: {class_names}\")\n",
        "\n",
        "# Count classes in training set\n",
        "unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
        "print(f\"Training set distribution:\")\n",
        "for class_idx, count in zip(unique_train, counts_train):\n",
        "    class_name = class_names[class_idx]\n",
        "    percentage = (count / len(y_train)) * 100\n",
        "    print(f\"  {class_name}: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "# Count classes in test set\n",
        "unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
        "print(f\"Test set distribution:\")\n",
        "for class_idx, count in zip(unique_test, counts_test):\n",
        "    class_name = class_names[class_idx]\n",
        "    percentage = (count / len(y_test)) * 100\n",
        "    print(f\"  {class_name}: {count} ({percentage:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze TF-IDF features\n",
        "print(\"üîç TF-IDF Feature Analysis\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Get feature names\n",
        "feature_names = fitted_preprocessor.get_feature_names()\n",
        "print(f\"Total features created: {len(feature_names)}\")\n",
        "\n",
        "# Show sample features\n",
        "print(f\"\\nüìù Sample Features:\")\n",
        "print(\"=\" * 30)\n",
        "print(\"First 20 features:\")\n",
        "for i, feature in enumerate(feature_names[:20]):\n",
        "    print(f\"{i+1:2d}. {feature}\")\n",
        "\n",
        "print(f\"\\nLast 20 features:\")\n",
        "for i, feature in enumerate(feature_names[-20:], len(feature_names)-19):\n",
        "    print(f\"{i:2d}. {feature}\")\n",
        "\n",
        "# Analyze feature sparsity\n",
        "print(f\"\\nüìä Feature Sparsity Analysis:\")\n",
        "print(\"=\" * 40)\n",
        "sparsity = 1.0 - (X_train.nnz / float(X_train.shape[0] * X_train.shape[1]))\n",
        "print(f\"Sparsity: {sparsity:.3f} ({sparsity*100:.1f}% of values are zero)\")\n",
        "print(f\"Non-zero values: {X_train.nnz:,}\")\n",
        "print(f\"Total possible values: {X_train.shape[0] * X_train.shape[1]:,}\")\n",
        "\n",
        "# Show most common features (highest mean TF-IDF scores)\n",
        "print(f\"\\nüèÜ Most Important Features (by mean TF-IDF score):\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Calculate mean TF-IDF scores\n",
        "mean_scores = np.array(X_train.mean(axis=0)).flatten()\n",
        "top_indices = np.argsort(mean_scores)[-20:][::-1]\n",
        "\n",
        "for i, idx in enumerate(top_indices, 1):\n",
        "    feature = feature_names[idx]\n",
        "    score = mean_scores[idx]\n",
        "    print(f\"{i:2d}. {feature:25s} (score: {score:.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Data Quality Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive data quality visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. Text length distribution after preprocessing\n",
        "df_processed['text_length_processed'] = df_processed['review'].str.len()\n",
        "positive_lengths_proc = df_processed[df_processed['sentiment'] == 'positive']['text_length_processed']\n",
        "negative_lengths_proc = df_processed[df_processed['sentiment'] == 'negative']['text_length_processed']\n",
        "\n",
        "axes[0, 0].hist([positive_lengths_proc, negative_lengths_proc], bins=50, alpha=0.7, \n",
        "                label=['Positive', 'Negative'], color=['lightblue', 'lightcoral'])\n",
        "axes[0, 0].set_xlabel('Text Length (characters)')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].set_title('Text Length Distribution After Preprocessing', fontweight='bold')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].set_xlim(0, 1000)\n",
        "\n",
        "# 2. Feature importance (top 15 features)\n",
        "top_15_indices = np.argsort(mean_scores)[-15:][::-1]\n",
        "top_15_features = [feature_names[i] for i in top_15_indices]\n",
        "top_15_scores = [mean_scores[i] for i in top_15_indices]\n",
        "\n",
        "axes[0, 1].barh(range(len(top_15_features)), top_15_scores, color='skyblue')\n",
        "axes[0, 1].set_yticks(range(len(top_15_features)))\n",
        "axes[0, 1].set_yticklabels(top_15_features)\n",
        "axes[0, 1].set_xlabel('Mean TF-IDF Score')\n",
        "axes[0, 1].set_title('Top 15 Most Important Features', fontweight='bold')\n",
        "axes[0, 1].invert_yaxis()\n",
        "\n",
        "# 3. Sparsity visualization\n",
        "sparsity_data = [sparsity * 100, (1 - sparsity) * 100]\n",
        "labels = ['Zero Values', 'Non-zero Values']\n",
        "colors = ['lightcoral', 'lightgreen']\n",
        "\n",
        "axes[1, 0].pie(sparsity_data, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90)\n",
        "axes[1, 0].set_title('Feature Matrix Sparsity', fontweight='bold')\n",
        "\n",
        "# 4. Train/Test split visualization\n",
        "train_size = len(y_train)\n",
        "test_size = len(y_test)\n",
        "split_data = [train_size, test_size]\n",
        "split_labels = ['Training Set', 'Test Set']\n",
        "split_colors = ['lightblue', 'lightgreen']\n",
        "\n",
        "axes[1, 1].pie(split_data, labels=split_labels, autopct='%1.1f%%', colors=split_colors, startangle=90)\n",
        "axes[1, 1].set_title('Train/Test Split (80/20)', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary statistics\n",
        "print(\"üìä Data Quality Summary:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Original dataset size: {len(df):,}\")\n",
        "print(f\"Processed dataset size: {len(df_processed):,}\")\n",
        "print(f\"Samples removed: {len(df) - len(df_processed):,}\")\n",
        "print(f\"Training samples: {len(y_train):,}\")\n",
        "print(f\"Test samples: {len(y_test):,}\")\n",
        "print(f\"Features created: {X_train.shape[1]:,}\")\n",
        "print(f\"Feature sparsity: {sparsity:.1%}\")\n",
        "print(f\"Average text length (original): {df['text_length'].mean():.1f} chars\")\n",
        "print(f\"Average text length (processed): {df_processed['text_length_processed'].mean():.1f} chars\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Summary and Next Steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the preprocessed data and preprocessor for use in other notebooks\n",
        "print(\"üíæ Saving Preprocessed Data\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs('../models', exist_ok=True)\n",
        "os.makedirs('../data', exist_ok=True)\n",
        "\n",
        "# Save the fitted preprocessor\n",
        "joblib.dump(fitted_preprocessor, '../models/preprocessor.joblib')\n",
        "print(\"‚úÖ Preprocessor saved to ../models/preprocessor.joblib\")\n",
        "\n",
        "# Save the processed data\n",
        "joblib.dump({\n",
        "    'X_train': X_train,\n",
        "    'X_test': X_test,\n",
        "    'y_train': y_train,\n",
        "    'y_test': y_test,\n",
        "    'feature_names': feature_names,\n",
        "    'class_names': class_names\n",
        "}, '../data/processed_data.joblib')\n",
        "print(\"‚úÖ Processed data saved to ../data/processed_data.joblib\")\n",
        "\n",
        "print(f\"\\nüéØ Preprocessing Summary:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"‚úÖ Dataset loaded and validated\")\n",
        "print(f\"‚úÖ Text cleaning and preprocessing applied\")\n",
        "print(f\"‚úÖ TF-IDF features created ({X_train.shape[1]} features)\")\n",
        "print(f\"‚úÖ Train/test split completed (80/20)\")\n",
        "print(f\"‚úÖ Data saved for model training\")\n",
        "print(f\"‚úÖ Ready for next step: Model Training!\")\n",
        "\n",
        "print(f\"\\nüìã Key Statistics:\")\n",
        "print(f\"   ‚Ä¢ Original samples: {len(df):,}\")\n",
        "print(f\"   ‚Ä¢ Processed samples: {len(df_processed):,}\")\n",
        "print(f\"   ‚Ä¢ Training samples: {len(y_train):,}\")\n",
        "print(f\"   ‚Ä¢ Test samples: {len(y_test):,}\")\n",
        "print(f\"   ‚Ä¢ Features: {X_train.shape[1]:,}\")\n",
        "print(f\"   ‚Ä¢ Feature sparsity: {sparsity:.1%}\")\n",
        "\n",
        "print(f\"\\nüöÄ Next Steps:\")\n",
        "print(f\"   1. Run notebook 02_model_training.ipynb\")\n",
        "print(f\"   2. Train multiple ML models\")\n",
        "print(f\"   3. Create ensemble model\")\n",
        "print(f\"   4. Evaluate model performance\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
